%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter2.tex
%% NOVA thesis document file
%%
%% Chapter with the template manual
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter2.tex}%

\chapter{Research Context}

TODO: A proper introduction to this

I think the CAP theorem can be included under consistency subsection, with a proper introduction/context. Likely will need to be shortened though.

I think I'll need to make more of a connection between these topics and PotionDB/choices in PotionDB. Checking our paper is a good way to see how that can be done.
Or maybe just leave that for the next chapter.

\section{CAP theorem}
\label{sec:cap}

In an ideal world, distributed systems would all provide strongly consistent data, be always available and keep operating even in the presence of failures and network partitions.
However, the CAP theorem \cite{cap} states that it is only possible to, at most, provide two out of the three following properties:
\begin{enumerate*}[label=(\roman*)]
	\item Strong \textbf{C}onsistency - all replicas of a system must provide the same view of the data at any given time;
	\item \textbf{A}vailability - the system is capable of providing a reply to every client's request at any point in time;
	\item \textbf{P}artition-tolerance - the system keeps operating and evolving state correctly even in the presence of message loss and network partitions.
\end{enumerate*}

Typically, since network partitions are common on systems distributed across multiple places \cite{understandingEC}, the choice tends to be between providing Strong Consistency or Availability.
It is noteworthy that one does not need to select ``all or nothing'' \cite{understandingEC}. 
Systems providing \textbf{C}onsistency and \textbf{P}artition-tolerance (CP), can still be available in the presence of some faults, but will eventually stop to evolve state if too many nodes fail or too many messages are lost \cite{cap}.
On the other hand, systems providing \textbf{A}vailability and \textbf{P}artition-tolerance can still provide some consistency guarantees, known as Weak Consistency. However, the replicas will diverge at times and conflicting states may be observed due to the concurrent execution of operations.

\section{Consistency}

%TODO: Put here a list of both strong and weak consistency models. "Just" use papers already used for other sections
%Cassandra may not really be needed. Dynamo may be useful for eventual; cops may be useful if I talk about causal+.

In the literature, a plethora of consistency models have been specified \cite{linearizability, si, spanner, understandingEC, cops, dynamo, cassandra}, each one providing different guarantees to the developers in terms of the states that can be observed, as well as different requirements to deploy such models.
Despite the variety of models, they can be grouped as either being a form of \emph{Strong Consistency} or \emph{Weak Consistency}.

\subsection{Strong consistency}

In models providing strong consistency, all clients observe the same state of the system independently of the replica contacted by the client(s).
In order to achieve this, it is necessary to totally order all write operations executed in the system, which requires coordination among the different replicas \cite{linearizability, spanner}.
Depending on the configuration of the system, even to execute a single read operation, many replicas may need to be contacted.
This is necessary as at any point it must be ensured that the client can read the latest state.

The strong requirements of coordination imply that strongly consistent systems, in order to tolerate network partitions, may have to come to an halt (unavailable) when enough replicas can not be contacted to execute an operation, in order to prevent state divergence or incorrect values being returned.
Strongly consistent systems tend to be easier to develop applications on than weaker consistency, as they are easier to reason about \cite{spanner}.
However, the costs of synchronization can be prohibitively high for large scale systems, specially if replicated across the globe, as latency for operations quickly racks up.
Due to the requirement of a total order, it also tends to be difficult to scale to many clients and maintain high throughput.

Multiple models implementing strong consistency have been proposed in the literature  \cite{linearizability, si}: serializability, linearizability and snapshot isolation to name a few.

\subsection{Weak consistency}

Models providing weak consistency are considerably more relaxed in terms of requirements compared to strong consistency \cite{understandingEC}.
As such, they also provide weaker guarantees, making them harder to reason about and build applications on.
For instance, concurrent updates on the same objects may lead to undesired results or values.
The states of the replicas may diverge, with read anomalies and ``illogical'' (in the context of an application) states being observed.
For example, in a group communication system, under some consistency models, user A may see user B replying to user C's message before he even sees user C's message.
This can be very confusing to the users.
However, the weaker requirements of weakly consistent systems gives potential to many advantages compared to strong consistency: better fault tolerance (operations can keep executing even under network partitions), lower latency and higher scalability in terms of throughput and number of clients.

One of the most basic consistency models is eventual consistency \cite{understandingEC}.
In short, eventual consistency provides only one guarantee: when updates stop occurring, eventually the state of the replicas will converge.
However, several issues are left in the open. For example: what happens when the same object is concurrently updated? Which states can be observed on reads? How do the states evolve as updates are being applied?

Many other weak consistency models have been studied in the literature \cite{understandingEC, session, cops, dynamo, cassandra, walter}, e.g. causal consistency, causal+, monotonic reads, PSI, etc.
Causal consistency is of particular interest as it provides useful guarantees.
In a general form, causal consistency ensures that operations casually related  \cite{lamport2019time}, i.e. in which one happens before the other, are seen according to said order by every client.
This means that, e.g., a read that happens after a write must reflect the effects of said write.
With causal consistency, the aforementioned example of group communication system would no longer be possible - user C would always see user B's reply after seeing user A's message, as they are causally related \cite{lamport2019time, walter}.

\todo{Any system that provides causal consistency on the level of a single object only? I couldn't find any other than... a CRDT itself.}

Causality can be provided either in the context of a single object (i.e., causality between different objects is not ensured) or between multiple objects \cite{understandingEC}.
The former is tougher/costly to maintain, as an order needs to be maintained between all objects, but more useful.
For example, in a online shopping system which allows users to keep track of when a product is restocked, it is desirable for the notifications sent to the users to be causally related with the restocking action (as we do not want users to receive the notification before they can see the product in stock).
For this use case, causality between objects is desirable.

Causal+ consistency \cite{cops} still applies the same ideas of causal consistency, but also ensures the replicas do not diverge forever, by applying techniques to solve concurrency conflicts deterministically in all replicas.
By definition, causal consistency does not ensure replicas converge \cite{cops}.

Monotonic reads \cite{session, understandingEC} gives one simple to understand guarantee: consecutive reads on the same object, must always return the same value or a more recent value.
This means that after a value is read, it is not possible to read again an older value.
It is however possible to read stale data, or keep reading the same value despite more recent values existing.
In distributed systems, it is important to define if this guarantee is given at a single server level or across servers, as the latter may imply having to wait for data to arrive and be processed if the client issues reads in different servers.

Snapshot Isolation (SI) is an interesting model.
The intuition behind SI is that each transaction sees a consistent view of the database \cite{si}.
To be more precise, it sees a ``snapshot'', where all the objects are at the same version and the database is in a consistent state.
Under SI the transactions in a replica are totally ordered, thus preventing concurrency conflicts when updating the same objects.
Reads on a transaction are executed on the snapshot, never blocking.
Writes are applied on a higher version when the transaction commits, if no other transaction that commited in the meantime modified the same objects.
However, some anomalities can still occour under SI.
E.g., consider two objects 'c' and 'd', and two transactions 'A' and 'B'.
Consider now that both transactions read 'c' with value of 5. 
If transaction 'B' updates 'c' to 10, and transaction 'A' reads 'c' and copies the value of 'c' to 'd', both transactions can commit.
However, it is possible for 'B' to be ordered before 'A' and yet, end up with 'c' = 10 and 'd' = 5.
This would not be possible under serialization.

Parallel Snapshot Isolation (PSI) is an extension of SI that allows transactions in different replicas to commit in different orders \cite{walter}.
This model is useful for weak consistency systems, as they can provide strong guarantees when clients access only one server and, for example, causality between updates on different replicas, thus still allowing high performance. \todo{I do critize this hybrid approach in the geo replication section.}

\todo{This text will most likely need to be changed depending on how the introduction is written.}
In PotionDB we provide PSI, with causal+ consistency (hereafter causal consistency) for transactions executed in different servers. Our causality guarantees are cross object.
The views provided in our system are directly co-related to the data of other objects, thus it is desirable that when a client observes a change in said objects, they can also observe the change in the views.
We provide causality even if the client contacts a different server.
\todo{Likely need a better way to talk about this challenge.}
Note that providing causal consistency is specially challenging in PotionDB's scenario, as data is partially replicated.
Thus, it is possible for views to be related with objects of different partitions, and there not exist a single server which has both the view and all said objects.
Causality must be ensured despite such difficulty, i.e., causality between objects that are not even replicated in the same server.

To accommodate use cases in which higher throughput is desirable and causality is not needed for the read, we also provide monotonic reads as long as the client is sticky to one server.
We note that even in this scenario, the client always reads state left by some commited transaction, i.e., there is no interferance  from ongoing transactions.

\subsection{CRDTs and other conflict resolution techniques}

%CRDTs/operational transformation
Both with eventual and causal consistency, concurrent updates on the same objects can occur and lead to conflicts \cite{understandingEC}.
For instance, if an element is concurrently added and removed from a set, it is not clear what should be the final state.
Concurrency conflicts need to be dealt with, in order for all replicas' state to converge.
Solutions for handling conflicts can range from totally ordering operations following some criteria (e.g., using logical clocks and replica IDs), letting the user/application deal with the conflicting state (e.g., in a register with concurrent writes, use application logic to decide which value to stay) or forcing all operations to be commutative (if operations commute then the result will be the same, independently of the order by which they are applied).

In PotionDB we make usage of CRDTs \cite{crdt} to represent our datatypes.
CRDTs, or \textbf{C}onflict-Free  \textbf{R}eplicated \textbf{D}ata \textbf{Types}, are data types designed to be used in large-scaled distributed systems offering weak consistency.
Concurrency conflicts are solved by the CRDT itself, by designing operations to be commutative.
Updates and reads can execute locally without synchronization, with all replicas of a CRDT eventually converging.
Updates get propagated asynchronously.
This allows for high availability and low latency on accessing CRDTs, as it is even possible to cache CRDTs on the client-side \cite{legion, swiftcloud, castineira2015collaborative}.
Multiple policies for handling conflicts are available for the same datatypes, allowing CRDTs to more easily adapt to the needs of each application \cite{crdtMultipolicy, crdt}.

Alternative solutions based on commutativity have been studied in the literature. 
One such solution is OT, \textbf{O}perational \textbf{T}ransformation \cite{ot, otCorrectness}.
The intuition behind OT is that conflicting operations can, when arriving on a replica, be ``transformed'' to be commutative and thus not conflict.
However, it is usually considered harder and more error-prone to design said transformations instead of, as in CRDTs, designing operations to be commutative from the start \cite{otCorrectness, crdt}.
We believe CRDTs' ease of use and flexibility with solving conflicts justify its usage over OT-based solutions in PotionDB.

\section{Antidote}

Does this actually need a section of its own? Or should I refer it alongside other solutions and give more detail to this one?

\section{Replication}

%Must talk here about replication, partial replication, non-uniform replication and geo replication. May also have to talk here about op vs state based CRDTs and potentially state machine replication.

In distributed systems, replication is essential to ensure data is available in multiple sites.
Depending on the system, replicating data may lead to higher fault-tolerance and/or lower latency when accessing data, as well as higher scalability.
However, it also implies higher storage, network and computational costs.

It is thus important to tailor replication specifically to the intended use-case of the system.
Factors like consistency model, fault model of the system, geo-distribution of the servers, read/write ratio and types of operation affect the choice on how to replicate data efficiently.
As will be seen in this section, in PotionDB we combine ideas from multiple concepts of replication to provide a novel replication model that is well suited for PotionDB's use case.

\subsection{Synchronous and asynchronous replication}

\todo{Please check this section carefully... I don't feel very secure about what I say in this section. Suggestions are more than welcome.}

In synchronous replication, an update must be replicated to other replicas and confirmed by a subset (usually a majority) of those replicas before the update is considered completed.
This is usually applied by strongly consistent systems in order to keep the replicas up-to-date and avoid concurrency conflicts \cite{dynamo, spanner}.
These systems usually employ mechanisms such as Paxos \cite{paxos} or Total Order Broadcast \cite{tob} to totally order the operations, or a ``master-slave'' model in order to sort the operations in one place.
Combining these mechanisms with synchronous replication allows to ensure that no operations are lost and clients always read the latest, correct state \cite{spanner}.

\todo{Is it worth it to make a small section to present more information on state machine replication and paxos?}

In asynchronous replication, an update can be confirmed before it is sent to other replicas.
This makes it ideal for weakly consistent systems as it allows them to quickly confirm operations to the clients \cite{cops}.
Replication happens in the background, possibly even delayed in order to allow grouping with other operations for efficiency \cite{dynamo}.

\todo{If I refer to Antidote/Cure, I can probably use that citation above.}

Synchronous replication provides strong guarantees about the state evolution of the systems, ensuring data and updates are not lost and always consistent.
However, having to wait for the confirmation of other replicas not only limits fault-tolerance \cite{spanner} but also raises considerably the latency of each operation when replicas are far-away, making it unusable for geo-distributed systems or scenarios where low latency is essential \cite{slog}.
\todo{After writing of geo-replication, can probably put here more references.}
Asynchronous replication can lead to lower latency and higher throughput executing operations, due to not having to wait for other replicas' replies.
It also has lighter network requirements.
However, state diversion and concurrency conflicts may happen due to the lack of coordination among replicas, which need to be dealt with \cite{dynamo}.
While asynchronous replication may lead to more fault-tolerant systems \cite{dynamo, cassandra, cops}, namely in the presence of network partitions, controversially it makes the fault-detection more difficult to detect, as replicas can take un-bounded amounts of time to reply \cite{cap}.

\todo{Either here or in Research Context I should mention we make usage of async replication and explain why (avoid latency increase from geo-replication; better fault tolerance; sync not needed for our use-case)}

\subsection{Operation and state based replication}

Replicas can be kept up-to-date in different forms.
One important decision is on how to propagate changes to the state.
In the literature, solutions for propagating changes are usually grouped as being \emph{state-based} or \emph{operation-based} \cite{crdt}.

\todo{Do I need to say that for state-based CRDTs, states should form a monotonic semi-lattice, and explain that? As in, should I go into detail?}
\todo{Also should this section be more CRDT-focused (as in, the case of CRDTs in particular) or generic (the generic concept of state-based/op-based replication)}
\todo{Finally, maybe this should be grouped with the CRDT section instead of replication section.}

\paragraph{State-based \cite{crdt}.} Updates are propagated by sending the entire object state to other replicas.
If updates can happen in multiple replicas, the coming state may have to be merged with the existing state, so that the effects of operations in the existing state are not lost.
This merges and state propagation must be done in such a way that it is guaranteed that, eventually, all replicas converge to the same state.
Extra care must be taken when applying consistency models stronger than eventual consistency.
E.g., in causal consistency, the merge must ensure causality is kept \cite{understandingEC}.

\paragraph{Operation-based \cite{crdt}.}
Updates are propagated by sending the operations directly (or their effects) to other replicas.
The receiving replicas must then apply the operations/effects on their own objects.
Care must be taken on how these operations are handled - depending on the consistency model, these operations may have to be delivered and applied according to some order, e.g., causal order or even total order.
It must also be ensured that every relevant operation is delivered everywhere, and conflicts from concurrency are handled properly to avoid states diverging forever.

\paragraph{CRDTs \cite{15}.}
CRDTs are classified based on their type of propagation: state-based CRDTs and operation-based CRDTs (op-based CRDT), respectively.

In state-based CRDTs, to ensure states converge eventually, it is necessary for the ordered states of an object to form a monotonic join semi-lattice, and the merge operation must compute a least upper bound \cite{crdt, stateCRDT}. The intuition behind these concepts is that, for any two states, a merged state can be calculated that is not older than either of the merging states, and reflects the effect of all operations applied on both states.
Since states can be merged in any order, eventual delivery of states to every replica is enough.
Note that it is not necessary for every single state to be delivered, but rather, enough recent states that ensure, when updates stop happening, that all replicas reach the most, and same, up-to-date state.

In op-based CRDTs, every update must be delivered to every replica.
Furthermore, if not all operations are commutative (usually it is only required for concurrent operations to be commutative), then casual delivery is required from the network.

\paragraph{Shortcomings and optimizations.}
Both approaches have shortcomings.
Operation propagation can overwhelm a system if updates happen too often (too many small messages), while propagating states can be too expensive with big states, leading to big messages for every small state changes.
Optimizations can be done for both cases.
For operations, multiple can be grouped in a single message and applied in a row.
For states, it is possible to calculate differences of states (delta) and send those differences instead of the whole state.
This solution has been studied in the literature \cite{deltaAlmeida, deltaVan}, with CRDTs based on deltas being known as delta-CRDTs. Delta-CRDTs present considerable reductions on the message size compared to state-based CRDTs, but also have complex specifications \cite{deltaAlmeida}. Also, keeping replicas correctly up-to-date is more challenging (namely in terms of causal consistency \cite{deltaAlmeida}).

\subsection{Partial replication}

Full replication is very popular in distributed storage systems \cite{sipre}. 
It allows for potentially high fault tolerance, as data is stored everywhere so many servers can be unavailable and, depending on the consistency model, still have the data reachable or, at least, safely stored.
Full replication also simplifies data access, as whenever updates or reads are issued, all data being accessed is present in one place.
However, it also comes with downsides: as the number of servers increases, more storage is needed, as all servers store all data.
Network and processing power costs also increase, as all servers either process updates to all objects or changes to their states \cite{sipre}.

As the number of servers and/or data-centers increases, replication costs may become prohibitively high.
In the literature two different mechanisms have been proposed to alleviate the replication costs:

\paragraph{Internal partitioning.}
The idea behind internal partitioning is to split the dataset inside each server/data-center, allowing the system to scale with respectively, multi-core CPUs or multiple machines.
Internal partitioning in the context of a data-center helps reduce the higher replication costs associated with increasing the number of servers, however it also introduces some overhead in accessing data across partitions \cite{dynamo, cops, mdcc}.
Synchronization between machines may be needed to execute transactions, but this may be acceptable as latency inside a data-center is low \cite{cops}.
While this process already helps in reducing the increasing replication costs, all data-centers still replicate all data (full replication), which may still waste storage and network resources.
Internal partitioning is often referred to as ``sharding''.
We also include under internal partitioning systems \cite{dynamo} in which each node is responsible for a subset of the data and replicates some other subsets for fault tolerance.
Under this replication scenario, however, it is difficult to provide good consistency guarantees or features such as transactions.

\paragraph{External partitioning}.
With external partitioning, each data-center may replicate a different subset of data.
This allows to further reduce storage, network and processing costs as, respectively, less data is stored, less updates need to be sent and processed in each data-center \cite{spanner, sipre}.
The replication mechanism associated with external partitioning is called partial replication.

Partial replication is thus of interest for large-scale services, in order to keep replication costs bearable as the number of data-centers increases.
It is even more useful for systems distributed all around the world (geo-distributed) in which there is locality on the data \cite{sipre, slog}.
E.g., in an international e-commerce application, data regarding customers, sales and stocks in Europe is likely not relevant in Asia.
With partial replication, the referred data could be replicated only in European data-centers and possibly one other region for fault tolerance.
Besides the aforementioned benefits of partial replication, another advantage also comes from this: if synchronization is required (e.g., to ensure strong consistency), transactions regarding European data only need to coordinate with European data-centers, instead of data-centers spread across the world \cite{spanner, sipre, slog}.
This can allow for lower latency and higher throughput.

On the other hand, external partitioning needs to be carefully done, taking in consideration application context.
As data-centers do not have all the data, it is of foremost importance to ensure that, for most transactions, the data accessed is all in a single data-center.
Otherwise, a transaction may require multiple data-centers to be contacted/synchronized with \cite{spanner, sipre, chronocache, slog}, even under weak consistency models such as causal consistency.
This may severely hinder throughput and lead to high latency, even under weak consistency models, which negatively affects the user experience \cite{eiger, mdcc}.
Thus, careful fine-tuning of the partition scheme is important, and studies have been done for systems to self-adjust to changes on access patterns, by automatically migrating data between data-centers \cite{slog}.
If there is no locality on data or some other criteria to externally partition data, full replication may be more appropriate, specially under weak consistency.

\todo{Do I need some concluding note here/reference to PotionDB? Is this too much information?}

%Need citation for the disadvantages/shortcoming of partial replication
%Need citation for the advantages
%Maybe list all (or some) papers that make use of partial replication

\subsection{Geo replication}

\todo{This introduction may not be needed depending on what I say on... the Introduction itself. Also when I did this introduction, geo replication's section was before partial replication... does this intro still make sense?}

Many Internet services nowadays are deployed on a global scale with millions of users from all over the globe.
This leads to large-scale services having data-centers spread across the globe (geo-distributed), in order to ensure low latency to all users, as well as provide solid fault tolerance.
However, deploying geo-distributed systems is challenging due to the high latency between faraway data-centers \cite{mdcc, eiger, chronocache, slog}. Availability is also difficult if strong consistency is desired, as previously discussed in Section \ref{sec:cap}.
Geo replication concerns all systems which have a need to have their data replicated in multiple parts of the globe, usually with some parts being faraway from each other and, thus, have to employ mechanisms to deal with high latency.

A related concept is wide-replication.
Wide-replication shares similar concepts with geo-replication, namely the existence of multiple data-centers in different places. 
However the distance is usually somewhat limited (e.g., all data-centers located in the United States).
Some systems in the literature have been designed with wide-replication in mind \cite{spanner, cops}.
In this scenario however, having to coordinate with more than one data-center may be acceptable, as the latency is still low enough \cite{spanner} (below 100ms\footnote{For instance: Amazon's AWS servers in the United States have below 70ms latency among themselves, while the European's servers have below 50ms.}).
In geo-replication, this may become prohibitively expensive, as latencies between faraway data-centers are in the hundreds of milliseconds, which can easily degrade the user experience \cite{mdcc, eiger, chronocache}.

\todo{Does that part of "below 100ms" need any citation? And the amazon examples in the footnotes, does that need citation? I took from here: https://www.cloudping.co/grid}

Given the reasons above, solutions designed with geo-distribution in mind are required.
Solutions offering strong consistency for geo-distributed scenario exist \cite{mdcc, slog}, but they usually have very high latency, reduced availability and possibly low throughput.
Some systems try to go around those shortcomings \cite{mdcc, chronocache, slog, walter}, e.g. by making use of locality with partial replication, but they still suffer from the same problems when data from multiple data-centers needs to be accessed.
Also, they tend to even have more limitations on availability of some data, as the partial replicas tend to be nearby.
Other systems offer strong consistency for data access in one data-center and weaker consistency for data access across data-centers \cite{cops, eiger, walter}.
While the trade-off is interesting, it still leads to applications having to deal with issues inherit to weak consistency. E.g., updates done in different data-centers will be replicated under weak consistency, thus clients still observe the effects of weak consistency.

Finally, solutions offering weak consistency are attractive for geo-replication, as they coupe more easily with high latency, partial replication and are more scalable with the number of users \cite{eiger, cure, walter}.
However, some systems offer only eventual consistency (e.g. Dynamo), which is difficult for application programmers to work with due to its very weak guarantees.
Thus, research has been done in trying to bring causal consistency to wide-distributed and geo-distributed systems \cite{cops, eiger, saturn, cure, walter}, with causality across objects, specially under partial replication, being challenging.
The weak consistency systems can provide very low latency due to usually not needing to coordinate with other servers, but even with causality, it can be difficult to program applications on top of such systems. %Should cite here the one system that tries to provide a relational view on geo distributed.

\todo{Not sure if the text below is necessary/should be in some other form. Likely need to revisit this after other chapters are written/developed}

PotionDB is a key-value store which is geo-replicated and allows to provide both partial replication and full replication.
System administrators can decide, for each group of objects, if they should be fully replicated or partially replicated, and, in case of the latter, in which servers each group should be replicated in.
PotionDB also makes usage of internal partitioning inside each server to make usage of multi-core CPUs.
The main challenge of PotionDB consists in providing consistent views that concern global data, under a form of weak consistency (causal consistency) and without all the required data being in a single server.
Provisioning of said views should only require interacting with a single server also, to ensure low latency.

\subsection{Non-uniform replication}

The usage of partial replication can already reduce networking and storage costs, by reducing the amount of places each object is replicated on.
However, it does not help with the case of popular objects that may have a big size or have a lot of updates.

\todo{A better example may be needed for this?}
Consider a worldwide e-commerce application, with hundreds of thousands of different products (like Ebay or Amazon).
A naive way to maintain a leaderboard of the ``top 10 most sold products'' would be to use an object which keeps a sum of how many units each product sold.
This would imply having to generate an update for this leaderboard whenever a product is sold somewhere, and have this update be propagated and processed everywhere.
However, the vast majority of the updates would not affect the visible state (the top 10) of the leaderboard - updates to an element not on top do not affect the result of reads of the said leaderboard.

Non-uniform replication \cite{nonUniform} is useful for situations as the one described above.
With non-uniform replication, only updates that may change the visible state of the objects would be propagated.
Other updates would only be stored locally (and potentially to a few other replicas for fault tolerance) for the case in which it may become relevant later on.
Using non-uniform replication, it is possible to save on both storage and network costs, as less operations are replicated, processed and stored.
In some objects, it is even possible to discard operations entirely \cite{nonUniform} - e.g., in an object responsible to keep the max number of sales in a day of a product, any number of sales of a day that is below the max does not need to be propagated and can be discarded.
In short, the idea behind non-uniform replication is to reduce the amount of data that needs to be propagated and stored, while still ensuring any query can be served fully at any replica.

Cabrita et. al. \cite{nonUniform, nonUniformThesis} propose some non-uniform CRDTs.
Namely, they propose Top-K, Top-Sum (similar to Top-K but supports increments to entries), histograms and a filtered set as CRDTs using non-uniform replication.
Another concept that is related is computational CRDTs \cite{computationalCrdt}.
The idea behind computational CRDTs is that, for some objects, the client is not interested in the actual state of the object but rather the result of some computation.
For example, in an object that keeps an average, the client is only interested in the average value - the values of each element that was added to the average is not relevant.
Thus, it is not necessary to keep each individual value, but rather enough information to calculate the result (in this case, the sum of all adds and the number of additions).

Both computational and non-uniform CRDTs are useful for PotionDB.
We can leverage on both concepts in order to supply many different kinds of objects, which allow us to provide very rich views or summaries of data. 
This, in turn, allows us to efficiently and easily answer many different kinds of queries, keeping the storage and network overheads low.
We have already developed new CRDTs based on these concepts, namely a max/min CRDT and an average CRDT.
We have also extended the design of TopSum CRDT to support decrements.
With the CRDTs already implement, many SQL-like function queries are already supported, such as \emph{order-by}, \emph{group by}, \emph{limit}, \emph{average}, \emph{sum}, etc.
%We also extended both TopK and TopSum to support extra ``data'' to each entry

\todo{Not sure if the text above should be here or in the research statement. Also should the research statement include an example of how we convert a query to objects in PotionDB?}

%Give examples of objects.
%Talk about computational CRDTs
%Explain how this helps PotionDB


%Idea: reduce storage and network costs (not every data needs to be replicated everywhere). However, still replicate enough data to reply to any query

%Mention about usefulness. Mention about some datatypes, both proposed in the paper and the ones I made. Mention about computacional CRDTs also having similar ideas (I'll need to check a paper on this). In the uniform paper they mention the similarities with computacional CRDTs (and how non-uniform is an extension of it).

%Will have to explain about the differences in states - same observable state vs same state.

%Mention how this can be combined with partial replication. And how it all fits in PotionDB.

%I might have to mention about non-uniform eventual consistency... but I'd rather not.

\subsection{Replication in PotionDB}
Is this needed? A subsection where I talk about the choices in PotionDB related with replication (or to be more precise, with the topics discussed before)? I feel like mentioning PotionDB in some of the subsections is enough, and likely it should be more detailed in the Research Statement instead of this state of the art.
%Likely not needed and I should just mention as we go by how we use each kind of replication.

%General introduction about why replication is needed, its usage/beneficts and also costs
%Then go into each category of replication. Async vs sync? Then geo? Then partial? Then op vs state CRDT and end with non-uniform?

\section{Data access}

Most online services nowadays require storage solutions in order to support said services.
Often, databases are leveraged on in order to store and provide an interface to access the service's data.
E.g., in an e-commerce application, databases may be used to store the stocks of products, shopping carts, customer information, etc.
It is expected for databases to provide an easy and quick access for data, while also managing how the data is stored and kept consistent.

While many solutions for presenting data exist, two of the most common ones are key-value stores and relational databases.

\paragraph{Key-value stores.}
Most key-value stores present a very simple interface with two basic operations - \emph{get} and \emph{put}.
The former allows users to obtain the state of an object, while the latter updates or stores an object.
Each object is accessed by providing a key that uniquely identifies it.
Some databases only provide opaque objects, while others may provide more rich interfaces by supporting objects such as counters, maps and sets, alongside appropriate operations on those.
PotionDB provides a key-value interface, with support for many different kinds of objects, operations and even for materialized views.

\paragraph{Relational databases.}
Relational databases provide a so-called relational model.
In relational databases, data is organized in tables, with possible relationships between tables and the columns of different tables.
E.g., each entry in a table ``customers'' may refer to one or more entries in the table ``addresses''.
Usually, columns represent the fields of a table, while each row represents one entry (data) in the table.
Many systems provide SQL (\textbf{S}tructured \textbf{Q}uery \textbf{L}anguage) to define and access the data, which allows for a rich interface in accessing data and easy processing of said data.
For example, with a SQL query, it is possible to obtain directly from the database the average of salaries of users in a given company.
In comparison, in key-value stores, usually one would have to obtain multiple objects, calculate the average and then present the result, or store the pre-calculated result under some key.

Key-value stores are easier to implement.
Due to their simplicity, it is often easier to provide good performance, and is often applied by weak consistent systems.
On the other hand, relational databases have a richer interface, which eases application development, but are tougher to design and optimize for, being mostly used by databases providing strong consistency.
Some key-value stores provide extra features in order to facilitate application development by, e.g., providing many object types and extra operations.

\subsection{Queries}

%Key-value stores typically offer simple interfaces, often gets and puts of data blobs. %Need a citation for this. Check some paper that claims this is not rich enough.
%However, this makes application development more difficult, as relationships between objects and their correctness have to be maintained by the application logic.
%This makes the relational model often provided by strong consistency systems interesting, as it eases application development.

%One way to ease this is to provide a key-value store with a rich interface - e.g., by providing many kinds of different objects and different reads/update operations.
%This still maintains the ease of development and high performance of key-value stores, while also easening application development.
%To achieve this, it is important to consider which kind of operations are often used by applications.
Applications access data in different ways.
Some may mostly access the data directly, e.g., fetch information about a product in an e-commerce system.
Others may require summaries, aggregations, sorting of data or even more complex processing.

\textbf{O}n\textbf{l}ine \textbf{A}nalytical \textbf{P}rocessing, OLAP, is a method which consists on ways to analyse and organize data by executing analytical queries.
These kind of queries are often used in the context of marketing, financial report or business decisions.
For example, in an e-commerce system, it may be useful to know the most popular products at any given moment, in order to keep their stock available and e.g. adjust prices or advertisement.
This poses a challenge, as very large amounts of data need to be analysed (all sales), with updates often occurring (new sales, new products) and in short periods of time (information needs to be available fast to make a decision while it is still relevant).
Views, indexes and windowed data are some of the most common methods to provide these kind of queries.
Operations such as table joins, sums/averages of data, sorts, limits, group by and others are used by this kind of queries.

The TPC-H benchmark provides a specific example for a database managing sales data which aims to provide useful information for business decisions.
The queries listed in said benchmark provide a good example of the kind of queries executed in analytical scenarios.
One key requirement of analytical queries nowadays is to provide useful information with queries of quick execution, while many updates are happening on the background.

\todo{Maybe the paragraph below, or parts of it, should be in the research statement}
PotionDB is a geo-distributed database which aims to provide low latency for recurring queries.
Analytic queries fit such criteria (e.g., checking the most sold products is a recurring query).
We aim at providing such queries with a very low latency, similar to a normal query, while keeping the costs on storage low (partial + uniform replication).
As of now, PotionDB already supports many different kinds of CRDTs, providing solutions to answer queries often executed in OLAP scenarios.
Support for operations such as the ones referred before are already provided, and it is possible to support more if needed by adding new CRDTs to represent different kinds of objects or operations.
 

%Maybe end with a concluding note that later on more research can be done to find more types of applications/operations we may want to provide support for, or that PotionDB is extensible (e.g. - add more CRDTs)

%I might have to look into "OLAP". Online Analytical Processing. So for stuff like data mining, report writting, business reporting for sales, marketing, management, etc.

%Maybe I can start by looking into the SQL language. Then some papers providing strong consistency/SQL-like languages. There's one paper too providing weak consistency with relational model. Then also those papers of analytic queries/ChronoCache.

%Can't find anything in the existing papers. Will have to search some other way. I did find at least a few systems supporting materialized views.

\subsection{Speeding up queries - views and indexes}

In order to provide applications with easier and quicker access to data, mechanisms have been studied to complement direct data access.
Some of those mechanisms include usage of key-value stores as caches, indexes, views, data streaming, etc.
\todo{I probably need something more here to finish the paragraph... suggestions?}

\paragraph{Indexes.}
An index is a record whose goal is to speed up how quickly data is found.
In the context of a relational database, an index can be done on a column of a table to provide a quick way to access data by some criteria other than the primary key.
E.g., an index on users' data may provide quick access by phone number.
It can also be used to help group data in groups or sort more efficiently.
In non-relational databases, an index can point to the location of certain items.
E.g., a map can store all the keys of users, and each key can then be used to directly access the data of a given user.
Multiple systems implement indexes of various kinds to help speed up queries and data access.
Efficiently designing, using, storing and maintaining indexes is a common research topic.

\paragraph{Views.}
A view consists in a different way to present data.
In the context of databases, it is defined as being the result of some query.
Views can be used to filter data (e.g., only show users with age above a certain value), or to accommodate subqueries that may be used by other queries (e.g., a join of two tables in the case of a relational database).
Thus, in many databases, the main usage of a view is to simplify application development, by letting users define views which act as if they were ``virtual tables'' that do not use storage space but can be used freely in queries.
These views are re-calculated every time they are used.
Materialized views, on the other hand, are used with the goal of speeding up queries.
Materialized views cache the results of a given query, thus they can provide much quicker access to data, avoiding having to re-execute certain queries all the time.
However, it comes with its downsides - extra disk storage is needed and maintaining the views consistent and automatically updated is challenging, thus few systems implement them.

\todo{Not sure if the paragraph below should be here... or, at least, in this kind of form.}
PotionDB proposes to provide support for materialized views.
Materialized views have the potential to answer queries that could take a long time to process in few milliseconds.
Given PotionDB's geo-distributed, partial replicated nature, the main aim with materialized views is to provide quick and efficient access to data that, without a view, could imply a long and complex query execution across many servers.
Another goal is to provide such views without requiring all the data referred by a view to be replicated everywhere, thus saving in storage and replication processing costs.
The views themselves should, however, be replicated everywhere relevant to provide low latency access to them.
This is thus a quite challenging and novel problem - to the best of our knowledge, PotionDB is the first system to propose providing materialized views in a geo-distributed, partially replicated, weakly consistent scenario.
The challenge comes from multiple aspects.
PotionDB's materialized views should have a low storage footprint compared to the data they refer.
Also, views may refer to data that is spread across many servers, without a single server having all the data required to compute the entire view.
Furthermore, it is essential for a view to be able to provide a reply to a query without executing complex computations or any communication (e.g., fetching data) with other servers \todo{Not sure if this part of ``without executing complex computations'' is clear.}.
Finally, our views must also be kept up-to-date and provide causal consistency.

\section{Existing systems}

I need a better title for this... but basically present here some systems. Maybe refer some generic systems, then focus on ones trying to provide views/efficient queries for large scale.

Something to consider. Maybe name the Query section as ``Data Access''. Then put this and views as subsections and here show data storage systems and views solutions and such?

\section{Thoughts}

So here it is basically a very extended state of the art (similar to how I did in my master's? A bit smaller though)
Which topics do I want to touch about here?
\begin{itemize}
	\item CAP
	\item Consistency levels (probably a lot to cover here - from weak to strong, multiple types of weak, causality between objects/same object, etc.)
	\item CRDTs
	\item Antidote.
	\item Partial replication
	\item Non-Uniform replication
	\item Geo replication
	\item State partition???
	\item Views/indexes. Namely materialized views.
	\item Maybe typical database queries/operations (limit, sort by, etc.)? Has some relevance as we aim to provide views with CRDTs.
	\item Other similar solutions (ChronoCache, etc. Check the paper). Must definitely mention things like Noria and predictive treaties.
\end{itemize}

What about subsections?
\begin{itemize}
	\item Replication
	\item Consistency (can probably include CAP and state partition?)
	\item Other solutions?
\end{itemize}

For consistency, I can check Albert's PHD plan for references. Same for conflict resolution techniques in CRDTs.
Check our paper and my master's thesis for more topics/references too.

Note: On research statement, I can talk about TPC-H, and even give an example on how to transform a TPC-H query into CRDTs.
%\chapter{NOVAthesis Template \emph{User's Manual}}
%\label{cha:users_manual}

This phrase from the grant documents can be useful:
''In this work we propose to design a novel replication model levering on the advantages of both partial and non-uniform replication. We will also conduct research on integrating multiple consistency models in our proposal, which is challenging due to transactions spanning multiple partitions and materialized views referring to multiple partitions. We will also implement our model in a database prototype.´´

To talk about how difficult/novel the problem is, mention that: - we combine partial + uniform replication (novel) in a geo-distributed scenario + has to handle consistency for transactions spanning multiple partitions, ensuring both partially replicated objects and materialized views stay updated and correct.

Check the FCT grant docs for objectives/contributions too (dynamic partition (add/remove replicas on the fly), stronger consistency models are particularly interesting to mention.)

May be worth mentioning my Master's work (and the published paper) - if needed, I have the knowledge and experience to design new CRDTs, and also understanding of consistency levels.
